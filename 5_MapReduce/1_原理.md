

# MapReduce

	MR原语：map + reduce 

	输入(格式化k,v)数据集map映射成一个中间数据集(k,v)
	
	reduce (sql)  特征值 计算值
	“相同”的key为一组，调用一次reduce方法，方法内迭代这一组数据进行计算 (类似的sql)  并行执行

# 架构
    
    obClient：提交作业；
    JobTracker：初始化作业，分配作业，TaskTracker与其进行通信，协调监控整个作业；
    TaskTracker：定期与JobTracker通信，执行Map和Reduce任务；
    HDFS：保存作业的数据、配置、jar包、结果；
    


# 主线

map reduce

# 细节

split map shuffle reduce 

# split

	block split  逻辑分隔 避免block过大
	
	一个split对应一个map
	
	

# Map

	将数据制作为对应的映射
	
	并将映射写入缓冲区（缓冲区满了将溢出为文件）
		
	根据key分组
	map
	
	1. map任务处理
    1.1 对输入文件的每一行，解析成key、value对。
    每一个键值对调用一次map函数。
    1.2 写自己的逻辑，对输入的key、value处理，转换成新的key、value输出。
    
	
# shuffle

shuffle的过程对多个map任务的输出进行合并、排序

缓冲区

排序

	排序分组 减少

	两次排序

	按reduce分区进行排序
	考虑一个reduce处理多个key的情况 内部在排序
压缩

	提前计算
	

文件归并排序

	缓冲区满了 生成了多个文件 统一发送

# Reduc

	获取到全部的key对应的

	同一组key 只能在一个 reduce处理
	一个reduce能处理多组key
	Reduce merge  


 
#计算向数据移动

	将maptask reduce task 向 block 所在服务器移动
	
7.JobTracker
       JobTracker守护进程是应用程序和Hadoop之间的纽带.一旦提交代码到集群上,JobTracker就会确定执行计划,包括决定处理哪些文件,为不同的任务分配节点以及监控所有任务的运行.如果任务失败,JobTracker将自动重启任务,但所分配的节点可能会不同,同时受到预定义的重试次数限制.
       每一个Hadoop集群只有一个JobTracker守护进程,它通常运行在服务器集群的主节点上.
8.TaskTracker
       与存储的守护进程一样,计算的守护进程也遵循主从架构:JobTracker作为主节点,监测MapReduce作业的整个执行过程,同时,TaskTracker管理各个任务在每个从节点上的执行情况.
       TaskTracker的一个职责就是负责持续不断地与JobTracker通讯.如果JobTracker在指定的时间内没有收到来自TaskTracker的心跳,它会假定TaskTracker已经崩溃了,进而重新提交相应的任务到集群的其他节点中.


	
 	
